# NanoGPT base

In this repo, we try to replicate NanoGPT with modern techniques (without techniques overoptimized for the run)

To emulate a H100 environment (used in actural record runs), we do gradient accumulation (to have effective batch size similar to what is used in a real run)

We will also not use unsloth

# Results
